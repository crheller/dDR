{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dDR demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "from dDR.dDR import dDR\n",
    "from dDR.utils.plotting import plot_stim_pair_dDR, compute_ellipse\n",
    "from dDR.utils.decoding import compute_dprime\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate simulated spike count data\n",
    "* 100 neurons ($N$), 200 repetitions ($k$), 4 stimuli ($S$)\n",
    "* One latent, simulus-independent, noise dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data dimensions\n",
    "N, k, S = 100, 200, 4\n",
    "\n",
    "# Build rank 1 covariance matrix from latent variable\n",
    "lv = np.abs(np.random.normal(1, 0.75, (N, 1))) #lv w/ mostly positive weights\n",
    "lv = (lv / np.linalg.norm(lv)) * 2\n",
    "cov = lv.dot(lv.T)\n",
    "\n",
    "# add small random noise to covariance matrix to make full rank\n",
    "cov += np.random.normal(0, 0.1, cov.shape)\n",
    "\n",
    "# force to be positive semidefinite\n",
    "cov = cov.dot(cov.T)\n",
    "\n",
    "# define a dummy stimulus response -- each neuron responds differently to each stimulus -- \n",
    "# somewhat aligned with the latent \"noise\" dimensions\n",
    "sdrive = np.abs(np.random.normal(0, 0.75, (N, S))).T # different \"best\" stimulus for each unit\n",
    "\n",
    "# create data set from multivariate gaussian (neuron x rep x stimulus)\n",
    "X = []\n",
    "for s in range(S):  \n",
    "    # get mean response to stimulus for each neuron\n",
    "    u = sdrive[s, :]\n",
    "    X.append(np.random.multivariate_normal(u, cov=cov, size=(k)))\n",
    "X = np.stack(X).transpose([-1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "rd = plt.subplot2grid((2, 2), (0, 0), colspan=2) # display \"raw\" data\n",
    "pcplot = plt.subplot2grid((2, 2), (1, 0))        # plot \"responses\" in PC space, for visualization\n",
    "Nscree = plt.subplot2grid((2, 2), (1, 1))        # plot the variance explained by each stimulus-independent PC\n",
    "\n",
    "# plot the data (mean responses)\n",
    "rd.imshow(X.transpose([0, 2, 1]).reshape(N, -1), aspect='auto', cmap='Greys', vmin=0)\n",
    "for i in range(S):\n",
    "    rd.plot(np.arange(i*k, (i+1)*k), (-5)*np.ones(k), lw=5, label=r\"$S_{%s}$\"%i)\n",
    "rd.legend(frameon=False, bbox_to_anchor=(1, 1))\n",
    "rd.set_xlabel(r'Stimulus-by-repetition ($S$x$k$)')\n",
    "rd.set_ylabel('Neuron')\n",
    "rd.set_title('Raw Activity')\n",
    "\n",
    "# Plot single trial data in the \"stimulus space\" (first two PCs of trial averaged activity)\n",
    "Xu = X.mean(axis=1, keepdims=True)\n",
    "evals, evecs = np.linalg.eig(np.cov(Xu.squeeze()))\n",
    "idx = np.argsort(evals)[::-1]\n",
    "evals = evals[idx]; evecs[:, idx]\n",
    "proj = (X - X.mean(keepdims=True)).T.dot(evecs[:, 0:2])\n",
    "for sr in range(proj.shape[0]):\n",
    "    pcplot.plot(proj[sr, :, 0], proj[sr, :, 1], '.', label=r\"$S_{%s}$\"%sr, alpha=0.5, markeredgecolor='none')\n",
    "    x, y = compute_ellipse(proj[sr, :, 0], proj[sr, :, 1])\n",
    "    pcplot.plot(x, y, color=pcplot.get_lines()[-1].get_color())\n",
    "pcplot.set_xlabel(r\"Stim. $PC_1$\")\n",
    "pcplot.set_ylabel(r\"Stim. $PC_2$\")\n",
    "pcplot.set_title(r\"Projection onto stimulus $PC$s\")\n",
    "pcplot.legend(frameon=False)\n",
    "pcplot.axis('square')\n",
    "\n",
    "# scree plot of noise space\n",
    "Xcenter = X - Xu\n",
    "evals, evecs = np.linalg.eig(np.cov(Xcenter.reshape(N, -1)))\n",
    "idx = np.argsort(evals)[::-1]\n",
    "evals = evals[idx]; evecs[:, idx]\n",
    "Nscree.bar(np.arange(len(evals)), evals / evals.sum(), \n",
    "                width=1, edgecolor='white')\n",
    "Nscree.set_title(\"Noise Space\\n(singe-trial activity)\")\n",
    "Nscree.set_ylabel(\"Variance explained\")\n",
    "Nscree.set_xlabel(\"Principal components\")\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform decoding analysis using $dDR$\n",
    "* We will focus on just a single pair of stimuli, $S_1$ and $S_2$\n",
    "\n",
    "#### Step 1:\n",
    "* Define response matrices $S_1$ and $S_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = X[:, :, 1] # Activity during stimulus condition 1\n",
    "S2 = X[:, :, 2] # Activity during stimulus condition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:\n",
    "* Split data 50/50 for estimation and validation sets for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eidx = np.random.choice(np.arange(k), int(k/2), replace=False)\n",
    "vidx = np.array(list(set(np.arange(k)).difference(eidx)))\n",
    "S1_est = S1[:, eidx]\n",
    "S2_est = S2[:, eidx]\n",
    "S1_val = S1[:, vidx]\n",
    "S2_val = S2[:, vidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:\n",
    "* Perform dimensionality reduction using $dDR$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dDR object\n",
    "ddr = dDR()\n",
    "\n",
    "# fit dDR to estimation data (needs to be shape <Observation X Neuron>), and project estimation data onto the new basis\n",
    "S1_est_ddr, S2_est_ddr = ddr.fit_transform(S1_est.T, S2_est.T)\n",
    "\n",
    "# also project validation data into ddr space\n",
    "S1_val_ddr = ddr.transform(S1_val.T)\n",
    "S2_val_ddr = ddr.transform(S2_val.T)\n",
    "\n",
    "# plot the data\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "ax[0].set_title(\"Estimation (fit) data\")\n",
    "plot_stim_pair_dDR(S1_est_ddr, S2_est_ddr, \n",
    "                    lab1=r\"$S_{1}$\", lab2=r\"$S_{2}$\", \n",
    "                    c1='tab:orange', c2='tab:green',\n",
    "                    lw=2, alpha=0.5,\n",
    "                    ax=ax[0])\n",
    "ax[1].set_title(\"Validation (test) data\")\n",
    "plot_stim_pair_dDR(S1_val_ddr, S2_val_ddr, \n",
    "                    c1='tab:orange', c2='tab:green',\n",
    "                    lw=2, alpha=0.5,\n",
    "                    ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4:\n",
    "* Measure decoding accuracy. \n",
    "    * We will use $d'^2$ as our decoding metric (ADD CITATION). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit decoding axis on est data, NOTE: matrices must be shape Dimension X Repetition \n",
    "est_results = compute_dprime(S1_est_ddr.T, S2_est_ddr.T) \n",
    "# evaluate on est data by projecting onto optimal decoding axis (wopt)\n",
    "val_results = compute_dprime(S1_val_ddr.T, S2_val_ddr.T, wopt=est_results.wopt)\n",
    "\n",
    "# to visualize, project the data onto the decoding axis, wopt\n",
    "bins = np.arange(-8, 8, 0.5)\n",
    "s1 = S1_val_ddr.dot(est_results.wopt / np.linalg.norm(est_results.wopt))\n",
    "s2 = S2_val_ddr.dot(est_results.wopt / np.linalg.norm(est_results.wopt))\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "ax.hist(s1, bins=bins, histtype='stepfilled', edgecolor='k', lw=2, alpha=0.5, color='tab:orange', label=r\"$S_1$\")\n",
    "ax.hist(s2, bins=bins, histtype='stepfilled', edgecolor='k', lw=2, alpha=0.5, color='tab:green', label=r\"$S_2$\")\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(r\"$d'^2 = $ %s\" % round(val_results.dprimeSquared, 3))\n",
    "ax.set_ylabel(\"Bin counts\")\n",
    "ax.set_xlabel(r\"Projection of spike counts onto $\\mathbf{w}_{opt}$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, we include `dDR.utils.decoding.compute_dprime` as a general purpose function for optimal linear decoding. For a pair of e.g. stimuli ($S_1$ and $S_2$), the function returns: \n",
    "\n",
    "1) Stimulus discriminability, $d'^2$\n",
    "\n",
    "2) The optimal linear decoding axis, $\\mathbf{w}_{opt}$\n",
    "\n",
    "3) The eigenvalues, $\\lambda$, and eigenvectors, $\\mathbf{e}$, of the stimulus-independent covariance matrix, $\\Sigma = \\frac{1}{2} (\\Sigma_1 + \\Sigma_2)$\n",
    "\n",
    "4) The similarity between the eigenvectors of $S_1$ and $S_2$ \n",
    "\n",
    "5) The signal axis, $\\Delta \\mathbf{\\mu} = \\mu_1 - \\mu_2$, where $\\mu_1$ and $\\mu_2$ are the mean responses under conditions 1 and 2, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions of dDR\n",
    "Two extensions of the $dDR$ method are discussed in the preprint text. Here, we briefly walk through minimal examples that illustrate how these can be implemented.\n",
    "\n",
    "### 1) Custom noise space estimation with latent variable methods\n",
    "The first extension we discuss suggests that $dDR$ can be modified to include arbitrary noise dimensions that replace the default noise dimensions identified using standard $dDR$ (which are identified using $PCA$). For example, you might be interested in how activity along a particular latent variable interacts with stimulus coding. Without going into the details of additional methods for latent variable estimation, we show how this could be implemented with the $dDR$ class using the same data as above.\n",
    "\n",
    "#### Step 1:\n",
    "Define the loading vector that describes your latent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_variable_axis = np.random.normal(0, 1, (1,N))           # in practice, you'd identify this axis using a latent variable method\n",
    "latent_variable_axis /= np.linalg.norm(latent_variable_axis)   # must have mag 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:\n",
    "Define the $dDR$ class using the new noise axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddr_lv = dDR(ddr2_init=latent_variable_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:\n",
    "Fit the new $dDR$ space. The custom noise axis (`latent_variable_axis`) will now, by definition, be included in the space defined by `ddr_lv.components_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddr_lv.fit(S1_est.T, S2_est.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Including additional noise dimensions\n",
    "The second extension we discuss is to incorporate additional noise dimensions into the $dDR$ composition. For example, if you have sufficient data that you can estimate multiple dimensions of covariability reliably, you may want to include these in your decoding analysis to see how they impact coding accuracy. Doing this with the $dDR$ class is simple.\n",
    "#### Step 1:\n",
    "Define the $dDR$ object, specifying how many additional noise dimensions you wish to include in the decomposition. `n_additional_axes=1` corresponds to an overall $dDR$ dimensionality of 3 (one signal axis, two noise axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddr_2noise = dDR(n_additional_axes=1)\n",
    "\n",
    "# fit \n",
    "ddr_2noise.fit(S1_est.T, S2_est.T)\n",
    "\n",
    "print(f\"There are now 3 dDR dimensions: \\n {ddr_2noise.components_.shape}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitlbhbconda24036fcfcfd640ba9a35104f79b2a162",
   "display_name": "Python 3.7.4 64-bit ('lbhb': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}